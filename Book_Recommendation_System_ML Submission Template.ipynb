{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1722173494074}],"collapsed_sections":["85gYPyotYoAp","RoGjAbkUYoAp","F6T5p64dYrdO","y-Ehk30pYrdP","GwzvFGzlYuh3","qYpmQ266Yuh3","_ouA3fa0phqN","Seke61FWphqN","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    - **Book Recommendation System**\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Unsupervised\n","##### **Contribution**    - Individual\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["**Project Summary: Building Book Recommendation System**\n","\n","**Objective:**\n","\n","The primary goal of this project was to develop a robust and accurate book recommendation system that enhances user experience by suggesting relevant books based on their preferences and past interactions. The system was designed to handle a large dataset of books, users, and ratings, and to provide personalized recommendations that align with individual user tastes.\n","\n","**Dataset:**\n","\n","The project utilized three key datasets:\n","\n","User Data: Containing information about the users, including user IDs and potentially other demographic details.\n","\n","Book Data: Including book titles, authors, publication years, publishers, and additional metadata.\n","\n","Rating Data: Consisting of user-provided ratings for various books, which formed the core interaction data for the collaborative filtering model.\n","\n","Approach:\n","\n","To maximize the recommendation system's effectiveness, a hybrid approach combining Collaborative Filtering and Content-Based Filtering was employed.\n","\n","**Collaborative Filtering (SVD):**\n","\n","Model Used: Singular Value Decomposition (SVD) was used to perform collaborative filtering. This model decomposes the user-item interaction matrix into latent factors, capturing the underlying patterns in user preferences and book characteristics.\n","\n","Tuning: Hyperparameter tuning was performed using GridSearchCV to find the optimal number of factors, learning rates, and regularization terms. The final model demonstrated a lower RMSE, indicating improved prediction accuracy.\n","\n","Evaluation Metrics: The model’s performance was evaluated using RMSE, MAE, Precision, Recall, and F1 Score. These metrics helped ensure that the model was not only accurate but also effective in making relevant recommendations.\n","\n","**Content-Based Filtering (FAISS):**\n","\n","Model Used: FAISS (Facebook AI Similarity Search) was utilized to perform fast, scalable content-based filtering. The content of the books was vectorized using TF-IDF, capturing the importance of various terms in the books’ metadata.\n","\n","Tuning: Hyperparameters such as the number of clusters (nlist) and the number of probes (nprobe) were tuned to optimize the search efficiency and accuracy. The evaluation was based on metrics like Mean Average Precision (MAP) to ensure high-quality recommendations.\n","\n","Explanation: TF-IDF weights and cosine similarity were key components in determining the importance of features, helping to identify which terms were most influential in recommending similar books.\n","\n","**Hybrid Recommendation System:**\n","\n","The final model was a hybrid of the above two approaches, combining the strengths of collaborative filtering (personalization based on user behavior) and content-based filtering (recommendations based on book content).\n","\n","Integration: The hybrid system integrated the predictions from both models, ranking recommendations based on the collaborative filtering score while ensuring relevance through content-based filtering.\n","\n","Impact: This hybrid model provided more accurate and relevant recommendations, improving user satisfaction and engagement, and ultimately driving positive business outcomes.\n","\n","**Model Explainability:**\n","\n","SHAP (SHapley Additive exPlanations): SHAP was used to interpret the model's predictions, providing insights into the importance of different features and latent factors. This helped in understanding why certain books were recommended to users, thereby increasing transparency and trust in the system.\n","\n","**Results:**\n","\n","Improved RMSE: The hybrid model achieved a lower RMSE compared to individual models, indicating more accurate predictions of user ratings.\n","\n","Enhanced Recommendations: The system provided more accurate and diverse book recommendations, resulting in higher user engagement.\n","\n","Positive Business Impact: The model’s improvements in accuracy and relevance led to better user satisfaction, potentially increasing book sales and platform engagement.\n","\n","**Conclusion:**\n","\n","The project successfully developed a sophisticated hybrid book recommendation system that effectively combines collaborative filtering and content-based filtering. Through careful tuning and evaluation, the model achieved a balance between accuracy and relevance, making it a valuable tool for enhancing user experience and driving business success. The use of model explainability tools like SHAP further added transparency, allowing stakeholders to understand and trust the recommendation process."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["**BUSINESS PROBLEM OVERVIEW**\n","\n","A book recommendation system aims to help readers discover books that align with their interests and preferences. By providing personalized suggestions, such systems enhance user engagement, increase customer satisfaction, and drive sales for bookstores or online platforms.\n","\n","Book recommendation systems are widely used across various industries to enhance user experience, drive sales, and promote engagement. By leveraging personalized recommendations, these industries can better serve their users and achieve their business objectives.\n","\n","Personalized recommendations enhance user satisfaction by helping readers find books that match their tastes, which can lead to increased customer loyalty.\n","Users are more likely to engage with a platform that understands their preferences and offers tailored suggestions.\n","Recommending books that align with user interests increases the likelihood of purchases, directly boosting sales.\n","Suggesting related books or genres can lead to additional sales from users who discover new interests.\n","\n","Personalized recommendations can be used in targeted email campaigns,\n"," improving the effectiveness of marketing efforts.\n","Efficient targeting reduces wasted marketing spend by focusing on users with a higher likelihood of conversion.\n","For businesses with extensive book catalogs, recommendation systems help users navigate the vast selection and find relevant titles quickly.\n","Automating the recommendation process ensures consistent and scalable personalization without the need for manual intervention."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["! pip install surprise"],"metadata":{"id":"7f5iJYD1o7nX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"id":"z3nrZ2lG-htA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import seaborn as sns\n","from datetime import date\n","from wordcloud import WordCloud\n","from scipy import stats\n","from sklearn.preprocessing import LabelEncoder\n","import string\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","import faiss\n","from surprise import Dataset, Reader, SVD, accuracy\n","from surprise.model_selection import cross_validate,train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support\n","from surprise.model_selection import GridSearchCV\n","from sklearn.metrics import average_precision_score"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","drive.mount('/drive')\n","users_df = pd.read_csv('/drive/My Drive/Users.csv')\n","books_df = pd.read_csv('/drive/My Drive/Books.csv')\n","ratings_df = pd.read_csv('/drive/My Drive/Ratings.csv')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","users_df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["books_df.head()"],"metadata":{"id":"Yhmh6Isy2bSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratings_df.head()"],"metadata":{"id":"NurYQSk52i7z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","print(\"Shape of User dataset\\n\", users_df.shape)\n","print(\"Shape of Book dataset\\n\", books_df.shape)\n","print(\"Shape of Rating dataset\\n\", ratings_df.shape)"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","# User Data\n","print(\"Information of User data\\n\")\n","users_df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Book Data\n","print(\"Information of Book data\\n\")\n","books_df.info()"],"metadata":{"id":"yVWehoq96u-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rating Data\n","print(\"Information of Rating data\\n\")\n","ratings_df.info()"],"metadata":{"id":"AmOqO2UZR0Xg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","print(users_df.duplicated().sum())\n","print(books_df.duplicated().sum())\n","print(ratings_df.duplicated().sum())"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["users_df.isnull().sum()"],"metadata":{"id":"qRe_VqrKE5eY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["books_df.isnull().sum()"],"metadata":{"id":"HWQKKth8F70e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratings_df.isnull().sum()"],"metadata":{"id":"CSRlSFbBGAoy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["To effectively work with dataset, it's essential to understand the data. Here's a summary of what I got about dataset.\n","\n","**1. Basic Structure**\n","\n","Dimensions: The dataset has three parts with different dimensions:\n","\n","User Data: (278,858 rows, 3 columns)\n","\n","Book Data: (271,360 rows, 8 columns)\n","\n","Rating Data: (1,149,780 rows, 3 columns)\n","\n","**2. Column Information**\n","\n","User Data Columns: Contains user-related information.\n","\n","Example: User-ID - has unique values, Location, Age\n","\n","Book Data Columns: Contains book-related information.\n","\n","Example: ISBN - has unique values(similar as book_id), book title, author, publication_year\n","\n","Rating Data Columns: Contains user ratings for books.\n","\n","Example: User-ID, ISBN, rating\n","\n","Datasets have 0 duplicates.\n","\n","**3 datasets, which contain the following columns with their respective missing values:**\n","\n","**User data contains following column with null values**\n","\n","Age             -       110762 null values\n","\n","**Book data contains following columns with null values**\n","\n","Book-Author     -       2 null values\n","\n","Publisher       -       2 null values\n","\n","Image-URL-L     -       3 null values\n","\n","\n"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","print(\"User dataset column\\n\",users_df.columns)\n","print(\"Book dataset column\\n\",books_df.columns)\n","print(\"Rating dataset column\\n\",ratings_df.columns)"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","users_df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ratings_df.describe()"],"metadata":{"id":"58hPoUktKH9E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**User ID**\n","\n","IDs range from 2 to 278,854, with a mean around 140,386.4 and substantial variation (std = 80,562.28).\n","\n","**Ratings:**\n","\n","Ratings are highly varied, with many zero ratings which may need further investigation. The mean rating is 2.87 with a standard deviation of 3.85, suggesting diverse user opinions.\n","\n","**Age:**\n","\n","The ages range from 0 to 244, with a mean age of 37.24 and a standard deviation of 14.25. The data includes extreme values which may be outliers or errors."],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["### **User dataset columns**\n","**User-ID** - Unique identifiers assigned to each user.\n","\n","**Location** - Location of the user.\n","\n","**Age** - Age of the user.\n","\n","### **Book dataset columns**\n","\n","**ISBN** - Books are identified by their respective ISBN.\n","\n","**Book_Title** - Title of the book.\n","\n","**Book-Author** - Represent the author of the book.\n","\n","**Year-Of-Publication** - Represents the year in which a book was published.\n","\n","**Publisher** - Represents the name of the publishing company or organization that published the book.\n","\n","**Image-URL-S** - URLs linking to cover images appearing in small.\n","\n","**Image-URL_M** - URLs linking to cover images appearing in medium.\n","\n","**Image_URL-L** - URLs linking to cover images appearing in large.\n","\n","### **Rating dataset column**\n","**User-ID** - Unique identifiers assigned to each user.\n","\n","**ISBN** - Books are identified by their respective ISBN.\n","\n","**Booking-Rating** - Represents the rating given to a book by a user.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"_7SRinndmKkm"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","for i in users_df.columns.tolist():\n","  print(\"No. of unique values in \",i,\"is\",users_df[i].nunique(),\".\")"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in books_df.columns.tolist():\n","  print(\"No. of unique values \",i,\"is\",books_df[i].nunique(),\".\")"],"metadata":{"id":"yrXm_FAiNShb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in ratings_df.columns.tolist():\n","  print(\"No. of unique() values \",i,\"is\",ratings_df[i].nunique(),\".\")\n"],"metadata":{"id":"F8N16u1DNSxG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"markdown","source":["**Merging User Data with Rating Data**:\n","\n","The pd.merge() function merges **ratings_df** with **users_df** on the **User-ID** column using a left join to ensure all ratings are retained, including those with missing user information.\n","\n","**Merging Result with Book Data:**\n","\n","The resulting dataset is then merged with **books_df** on the **ISBN** column using a left join to ensure all user-book rating pairs are retained, including those with missing book information.\n","\n","**Ensuring No Data Points are Lost:**\n","\n","**Left Joins:** Using how='left' in the merge operations ensures that all records from the left DataFrame are retained. This prevents loss of data points from the larger datasets.\n","\n","**Handling Missing Values:** After merging, there might be some missing values (NaNs) due to unmatched keys. These can be handled later based on the requirement."],"metadata":{"id":"m_hknsvPe5sY"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","print(\"User Dataset column names\\n\",users_df.columns)\n","print(\"Book Dataset column names\\n\",books_df.columns)\n","print(\"Rating Dataset column names\\n\",ratings_df.columns)"],"metadata":{"id":"b0uDw9-wbj09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge user_data with rating_data\n","user_ratings_merged = pd.merge(ratings_df, users_df, on='User-ID', how='left')\n","\n","# Merge the above result with book_data\n","final_merged_data = pd.merge(user_ratings_merged, books_df, on='ISBN', how='left')\n"],"metadata":{"id":"qdXGmf4pfB-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a copy of the current dataset and assigning to df\n","#df=final_merged_data.copy()\n","df=final_merged_data"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Handling missing values**"],"metadata":{"id":"ZeEyqgxgXDUl"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isnull().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(df.isnull(), cbar=False)\n","plt.title('Heatmap of Missing Values')\n","plt.show()"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Given that the book name is crucial for recommendations and understanding user preferences, it makes sense to drop entries where the book name is missing. This ensures that recommendation system is based on complete and meaningful data."],"metadata":{"id":"O1gwIsmKY2gw"}},{"cell_type":"code","source":["# Drop rows where Book-Title is missing\n","df = df.dropna(subset=['Book-Title'])"],"metadata":{"id":"A7SCnrGuXMa4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The \"Age\" column is crucial for recommendation system, as different age groups often have different preferences. To ensure accurate imputation and effective use of this data, I need to check the type of missing values and identify any outliers."],"metadata":{"id":"xZoDhQvOPhM5"}},{"cell_type":"code","source":["# Check the type of missing values in the Age column\n","missing_ages = df['Age'].isnull().sum()\n","print(f\"Missing values in Age column: {missing_ages}\")\n","\n","# Visualize the distribution of the Age column\n","plt.figure(figsize=(12, 6))\n","sns.histplot(df['Age'], bins=30, kde=True)\n","plt.title('Distribution of Age')\n","plt.xlabel('Age')\n","plt.ylabel('Frequency')\n","plt.show()\n","\n","# Identify outliers using a boxplot\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x=df['Age'])\n","plt.title('Boxplot of Age')\n","plt.xlabel('Age')\n","plt.show()"],"metadata":{"id":"-Pi6atRTZNzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Handling outliers\n","# Define the upper and lower bounds for acceptable age values\n","Q1 = df['Age'].quantile(0.25)\n","Q3 = df['Age'].quantile(0.75)\n","IQR = Q3 - Q1\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Cap outliers at the bounds\n","df['Age'] = np.where(df['Age'] < lower_bound, lower_bound, df['Age'])\n","df['Age'] = np.where(df['Age'] > upper_bound, upper_bound, df['Age'])\n","\n","# Visualize the distribution after capping outliers\n","plt.figure(figsize=(12, 6))\n","sns.histplot(df['Age'], bins=30, kde=True)\n","plt.title('Distribution of Age After Capping Outliers')\n","plt.xlabel('Age')\n","plt.ylabel('Frequency')\n","plt.show()"],"metadata":{"id":"GIEU6C9GQ6jT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Given that the \"Age\" column is crucial for your recommendation system and the distribution appears nearly normal after capping outliers, using median imputation for missing values is a suitable approach."],"metadata":{"id":"XfA1-LUlSlyz"}},{"cell_type":"code","source":["# Impute missing values with the median age\n","median_age = df['Age'].median()\n","df['Age'].fillna(median_age, inplace=True)"],"metadata":{"id":"xF-c4U6qRUje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dropna(inplace=True)"],"metadata":{"id":"gGMyWKgKSwvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Handling Unlikely Age Values in the Dataset**\n","Given the context of Age column, it is improbable that very young children (e.g., ages 2.5, 3, 4, 5, 6, 7, 8, 9) are providing book ratings. These values are likely outliers or errors in the data. Therefore, it's reasonable to filter out these unlikely age values to ensure the integrity of dataset."],"metadata":{"id":"dcgfhOf2c7K3"}},{"cell_type":"code","source":["df['Age'].unique()"],"metadata":{"id":"2KS0W-DqTjgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a reasonable age range for users who can give book ratings\n","min_age = 10  # Minimum plausible age\n","max_age = 100  # Maximum plausible age, assuming no one older than 100 is likely to give ratings\n","\n","# Filter out unlikely age values\n","df = df[(df['Age'] >= min_age) & (df['Age'] <= max_age)]"],"metadata":{"id":"PukAsWq7dxuT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Handling Invalid Book Ratings**\n","Since book ratings should be between 1 and 10, any rating with a value of 0 is invalid. Given the nature of ratings, it is generally more appropriate to remove rows with zero ratings, as imputing them might introduce bias or inaccuracies."],"metadata":{"id":"FRck4MmsiHd4"}},{"cell_type":"code","source":["print(df['Book-Rating'].unique())\n","# Remove rows with zero ratings\n","df = df[df['Book-Rating'] != 0]"],"metadata":{"id":"XnqMXliVd_KC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Handling Unusual Values / Outilers  in the Year-Of-Publication Column**\n","\n"],"metadata":{"id":"sU_bRaO2kzY7"}},{"cell_type":"code","source":["# Convert Year-Of-Publication to numeric\n","df['Year-Of-Publication'] = pd.to_numeric(df['Year-Of-Publication'], errors='coerce')\n","\n","# Visualize the outliers using a boxplot\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x=df['Year-Of-Publication'])\n","plt.title('Boxplot of Year-Of-Publication')\n","plt.xlabel('Year of Publication')\n","plt.show()"],"metadata":{"id":"e-nJW24JTzfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Year-Of-Publication'].unique()"],"metadata":{"id":"lvmirgYPjDSl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The values 1376, 2030, 2037, and 2050 etc. in the Year-Of-Publication column are indeed unusual and likely erroneous. Given that most books are published within a more recent time frame, it's reasonable to investigate and correct these values."],"metadata":{"id":"blwW1GdNVTgW"}},{"cell_type":"code","source":["# Calculate Q1, Q3, and IQR\n","Q1 = df['Year-Of-Publication'].quantile(0.25)\n","Q3 = df['Year-Of-Publication'].quantile(0.75)\n","IQR = Q3 - Q1\n","\n","# Calculate lower and upper bounds for outliers\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","print(\"Lower bound \",lower_bound)\n","print(\"Upper bound \",upper_bound)"],"metadata":{"id":"uoXIQZr0P6gV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Given that dataset contains recent publication years like 2020, it is reasonable to set a range that includes modern publication years. I have set a logical lower bound based on historical data and a reasonable upper bound close to the current year."],"metadata":{"id":"E6DWPu-dYjH3"}},{"cell_type":"code","source":["# Define a reasonable range for publication years\n","current_year = 2024\n","min_year = 1800  # Earliest plausible publication year\n","\n","# Convert Year-Of-Publication to numeric and remove rows with values outside the plausible range\n","df['Year-Of-Publication'] = pd.to_numeric(df['Year-Of-Publication'], errors='coerce')\n","df = df[(df['Year-Of-Publication'] >= min_year) & (df['Year-Of-Publication'] <= current_year)]\n","\n","# Ensure the column is of integer type\n","df['Year-Of-Publication'] = df['Year-Of-Publication'].astype(int)"],"metadata":{"id":"lqvCcouQRJNa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Creating New Feature Columns from Existing Columns**\n","Creating new feature columns from existing ones, can significantly improve the performance of machine learning models and provide deeper insights during data analysis.\n","\n","**Potential New Features to Create**\n","\n","**Book Age:**\n","\n","Calculated the age of the book from the publication year to understand how the book's age affects its popularity and ratings.\n","\n","**User Age Group:**\n","\n","Categorize users into age groups (e.g., children, teenagers, adults, seniors) to analyze preferences and behaviors by age group."],"metadata":{"id":"RK43K8TXMObx"}},{"cell_type":"code","source":["# Feature 1: Create a new column for the book age\n","# creating the date object of today's date\n","todays_date = date.today()\n","df['Book-Age'] = todays_date.year - df['Year-Of-Publication']\n","\n","# Feature 2: Create a new column for user age groups\n","# Define age group bins and labels\n","age_bins = [0, 12, 18, 35, 60, np.inf]\n","age_labels = ['Child', 'Teenager', 'Adult', 'Middle-aged', 'Senior']\n","\n","# Categorize users into age groups\n","df['Age-Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n","\n","# Verify the new columns\n","print(df[['Year-Of-Publication', 'Book-Age', 'Age', 'Age-Group']].head())\n"],"metadata":{"id":"Z1oU2b1Ib4oD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"n2qAz5v3Ur7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"2poysCiKUJyz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["### **Summary of Data Manipulations and Insights**\n","\n","Here's a detailed summary of the data manipulations performed and the insights gained from the dataset:\n","\n","### **Data Manipulations**\n","\n","**Handling Missing Values:**\n","\n","Age: Missing values in the Age column were imputed with the median value.\n","\n","Book-Title: Rows with missing Book-Title values were dropped, as they are essential for recommendations.\n","\n","**Outlier Detection and Handling:**\n","\n","Age: Outliers in the Age column were capped at the lower and upper bounds.\n","\n","Year-Of-Publication: Outliers were identified, and values outside the range of 1800 to the current year were removed.\n","\n","**Data Type Conversion:**\n","\n","Converted Age from float to int.\n","\n","Converted Year-Of-Publication from object to int after handling outliers and missing values.\n","\n","**Filtering Invalid Ratings:**\n","\n","Removed rows with Book-Rating values of 0, as ratings should be between 1 and 10.\n","\n","**Feature Engineering:**\n","\n","Book Age -  Created a new column Book-Age by calculating the age of the book from its publication year.\n","\n","User Age Group -  Created a new column Age-Group by categorizing users into age groups based on their age.\n","\n","\n","### **Insights Gained**\n","\n","**Age Distribution:**\n","\n","After handling outliers and imputing missing values, the age distribution of users shows a reasonable spread, indicating diverse user demographics.\n","\n","**Year of Publication:**\n","\n","Filtering out improbable publication years and focusing on a reasonable range (1800 to 2024) ensured that the dataset only includes valid publication years, enhancing the reliability of the analysis.\n","\n","**Book Ratings:**\n","\n","By removing invalid ratings (0), the dataset now only contains valid ratings between 1 and 10, which is crucial for accurate recommendations.\n","\n","**Feature Engineering Benefits:**\n","\n","Book Age -  This new feature can help analyze trends and user preferences based on the age of the book.\n","\n","User Age Group -  Categorizing users into age groups provides deeper insights into preferences and behaviors across different age segments, improving the recommendation system."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Histplot - Distribution of Book Ratings:"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["#visualization code\n","# Distribution of Book Ratings\n","plt.figure(figsize=(10, 6))\n","sns.histplot(df['Book-Rating'], bins=10)\n","plt.title('Distribution of Book Ratings')\n","plt.xlabel('Book Rating')\n","plt.ylabel('Frequency')\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["To understand the overall distribution of book ratings in dataset. The histplot reveals how ratings are spread across different values, helping to understand if there are biases or trends in user ratings."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?\n","Upon analyzing the distribution of book ratings, it is evident that the plot is right-skewed. This skewness indicates that most books received ratings between 6 and 10. Here’s a detailed interpretation of this observation:\n","\n","**Right-Skewed Distribution:**\n","\n","The histogram of book ratings shows a right-skewed distribution. This means that the bulk of the ratings are clustered towards the higher end of the scale (6 to 10), with fewer books receiving lower ratings.\n","\n","**Concentration of Ratings:**\n","\n","6 to 10 Range: A significant number of books have been rated between 6 and 10, indicating that users generally have a positive outlook towards the books they read.\n","\n","Few Low Ratings: There are fewer books with ratings below 6, which might suggest that users either do not rate books they dislike or the books in the dataset are of generally high quality."],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["The insights derived from the analysis of the book ratings distribution can indeed help create a positive business impact in several ways.\n","\n","1. Enhanced User Satisfaction and Engagement\n","\n","  **Business Impact:**\n","\n","  **Personalized Recommendations:** By understanding that users tend to rate books highly, the recommendation system can focus on suggesting similar high-rated books, thereby enhancing user satisfaction.\n","\n","  **Engagement:** Providing users with books they are more likely to enjoy increases the likelihood of continued engagement and use of the platform.\n","2. Improved Marketing and Promotion Strategies\n","\n","  **Business Impact:**\n","\n","  **Targeted Promotions:** Promote books that have received high ratings more prominently, as they are more likely to attract user interest and generate sales.\n","\n","  **User Testimonials:** Utilize positive ratings and reviews in marketing campaigns to build trust and attract new users.\n","\n","3. Increased Sales and Revenue\n","\n","  **Business Impact:**\n","\n","  **Sales Boost:** By recommending books that are similar to those with high ratings, users are more likely to make purchases, thereby increasing sales.\n","\n","  **Cross-Selling Opportunities:** Recommend high-rated books alongside other related products (e.g., merchandise, additional content), creating opportunities for cross-selling and upselling.\n","\n","4. Refined Content Acquisition Strategy\n","\n","  **Business Impact:**\n","\n","  **Content Curation:** Focus on acquiring and promoting books that align with user preferences, as indicated by high ratings. This ensures a curated selection that meets user expectations.\n","  \n","  **Supplier Relationships:** Strengthen relationships with publishers and authors of highly-rated books to secure more exclusive or early access to popular content.\n"],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Scatterplot - Age vs. Book Ratings:"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","# Age vs. Book Ratings\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='Age', y='Book-Rating', data=df, alpha=0.5)\n","plt.title('Age vs. Book Ratings')\n","plt.xlabel('Age')\n","plt.ylabel('Book Rating')\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["To analyze how book ratings vary with user age. The scatter plot can show if certain age groups tend to rate books higher or lower, indicating user preferences based on age."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["The scatter plot showing that users of all ages have given ratings from 1 to 10 provides valuable insights into user behavior and preferences.\n","\n","Insight: The fact that users across all age groups have given ratings from 1 to 10 suggests that the books available on the platform have a broad appeal, catering to diverse age groups.\n","\n","Insight: The variation in ratings across all age groups implies that individual preferences vary widely, regardless of age. This means that people of the same age group might have different tastes in books.\n","\n","Insight: Users from all age groups are actively engaging with the platform by rating books, indicating a healthy and engaged user base."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["**Business Impact:**\n","1. Enhanced Personalization:\n","Utilize the insight that preferences vary widely within age groups to enhance personalization algorithms. This means focusing on individual user behavior and ratings history rather than relying heavily on age as a predictor.\n","2. Targeted Marketing Campaigns:\n","Develop marketing campaigns that highlight the diversity of books available, showcasing that the platform caters to all age groups and tastes.\n","\n","3. User Retention Strategies:\n","  Implement user retention strategies that acknowledge the active participation of all age groups. For example, create age-specific reading challenges or book clubs to foster community engagement."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Scatterplot -  Book Age vs. Book Ratings:"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","# Create a scatter plot of Age vs. Book Ratings\n","plt.figure(figsize=(12, 6))\n","sns.scatterplot(x='Book-Age', y='Book-Rating', data=df, alpha=0.5)\n","\n","# Set the x-axis scale to start at 0 and have a gap of 10\n","plt.xticks(np.arange(0, df['Book-Age'].max() + 10, 10))\n","\n","# Add title and labels\n","plt.title('Book Age vs. Book Ratings')\n","plt.xlabel('Book Age')\n","plt.ylabel('Book Rating')\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["To investigate if there is a relationship between the age of the book and its ratings. Scatter plot can reveal if newer or older books tend to receive higher ratings, indicating potential biases toward newer releases or classics. It can easily visible with scatter plot."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["**Books Less Than 20 Years Old:**\n","\n","Observation: These books have ratings from a limited number of users.\n","\n","Insight: This could indicate that newer books are either not as widely discovered or not as extensively reviewed by users on the platform. It may also suggest that these books are still building their reputation and readership.\n","\n","**Books Aged 20 to 100 Years:**\n","\n","Observation: These books received ratings from many users, covering the full spectrum of ratings from 1 to 10.\n","\n","Insight: This indicates a strong interest and engagement with books that fall within this age range. It suggests that these books are well-established and have a broad appeal across the user base.\n","\n","**Books More Than 100 Years Old:**\n","\n","Observation: These books predominantly received high ratings, typically between 5 and 10. But these books have ratings from a few users.\n","\n","Insight: This suggests that very old books, likely classics or well-regarded historical works, are highly valued by users. These books may have stood the test of time and are appreciated for their enduring quality and significance."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["**1. Targeted Marketing Strategies:**\n","\n","  Highlight and promote books aged 20 to 100 years, as they are highly engaged with and span the full range of user ratings. Create marketing campaigns that emphasize the diversity and richness of these books.\n","\n","**2. Promotion of Classics:**\n","\n","  Create special collections or features for books that are more than 100 years old, emphasizing their high ratings and classic status.\n","\n","**3. Discovery of Newer Books:**\n","\n","  Implement recommendation algorithms and discovery features that help users find and rate newer books (less than 20 years old).\n"],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Barplot - Average Book Rating by Age Group:"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","# Average Book Rating by Age Group\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Age-Group', y='Book-Rating', data=df, estimator=lambda x: sum(x) / len(x))\n","plt.title('Average Book Rating by Age Group')\n","plt.xlabel('Age Group')\n","plt.ylabel('Average Book Rating')\n","plt.show()"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["To compare average book ratings across different age groups. The bar plot helps compare average ratings across different age groups, revealing which groups rate books more favorably."],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["**Consistent Positive Ratings Across Age Groups:**\n","\n","**Observation:** All age groups give average ratings between 7 and 8.\n","\n","**Insight:** This indicates a generally positive reception of the books available on the platform across different age demographics. It suggests that the platform’s book selection appeals broadly to users of all ages."],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["**Confidence in Current Catalog:**\n","\n","Maintain the diversity and quality of the current book catalog, as it is well-received across all age groups.\n","\n","**Tailored Marketing Campaigns:**\n","\n","Create marketing campaigns that highlight the overall high ratings of the platform's books, appealing to users of all age groups.\n","\n","**Enhanced User Experience:**\n","\n","Focus on maintaining and improving the user experience by ensuring the availability of high-quality books across various genres and categories that appeal to all age groups."],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Histplot - Distribution of Year of Publication:"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","# Distribution of Year of Publication\n","plt.figure(figsize=(10, 6))\n","sns.histplot(df['Year-Of-Publication'], bins=30, kde=True)\n","plt.title('Distribution of Year of Publication')\n","plt.xlabel('Year of Publication')\n","plt.ylabel('Frequency')\n","plt.show()"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["To examine the distribution of book publication years in the dataset. The histplot helps to plot distribution of publication years which can indicate trends over time and the dataset's focus on older or newer books."],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["**Concentration of Publications (1970-2010):**\n","\n","Observation: A significant number of books in the dataset were published between 1970 and 2010.\n","\n","Insight: This period likely represents a time of prolific book production, and these books may still be popular and relevant to readers today. It also suggests that the platform has a strong collection of books from this era."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["**Curated Collections and Recommendations:**\n","\n","Create curated collections of books from the 1970-2010 period and feature them prominently on the platform. Highlight these collections in recommendation algorithms.\n","\n","**Content Strategy and Acquisition:**\n","\n","Focus on acquiring more books that are either from this period or similar in style and themes to those popular between 1970 and 2010.\n","\n","**User Engagement Initiatives:**\n","\n","Launch reading challenges, book clubs, or discussion forums centered around popular books from the 1970-2010 period.\n"],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Stack plot - Top 20 books with rating of 10, 9, 8"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"code","source":["# Chart - 7 visualization code\n","# Filter the dataset for ratings of 10, 9, and 8\n","high_rate_df = df[df['Book-Rating'].isin([8, 9, 10])]\n","\n","# Calculate the frequency of each rating for each book\n","rating_frequencies = high_rate_df.groupby(['Book-Title', 'Book-Rating']).size().unstack(fill_value=0)\n","\n","# Calculate total ratings for each book to find the top 20 books\n","rating_frequencies['Total'] = rating_frequencies.sum(axis=1)\n","top_20_books = rating_frequencies.sort_values(by='Total', ascending=False).head(20)\n","\n","# Plot the rating frequencies\n","top_20_books.drop(columns='Total').plot(kind='bar', stacked=True, figsize=(14, 8), color=['#FF9999', '#66B3FF', '#99FF99'])\n","plt.title('Top 20 Books with Ratings of 10, 9, and 8 Along with Rating Frequency')\n","plt.xlabel('Book Title')\n","plt.ylabel('Frequency')\n","plt.legend(title='Book Rating', loc='upper right')\n","plt.xticks(rotation=90)\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t27r6nlMphqO"}},{"cell_type":"markdown","source":["A stacked bar chart provides a clear view of the top 20 books that received high ratings (8, 9, and 10). Its easy to visualize each rating frequency."],"metadata":{"id":"iv6ro40sphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"r2jJGEOYphqO"}},{"cell_type":"markdown","source":["**High Popularity of \"The Lovely Bones\":**\n","\n","Observation: \"The Lovely Bones: A Novel\" received significantly more high ratings (8 to 10) compared to other books.\n","\n","Insight: This indicates that \"The Lovely Bones\" is exceptionally popular among users, suggesting it has a broad appeal and is well-received.\n","\n","**General Positive Reception of Books:**\n","\n","Observation: Most books receive high ratings (8 to 10) from around 200 users.\n","\n","Insight: This suggests a generally positive reception of books on the platform, indicating that users are finding and enjoying books that meet their expectations."],"metadata":{"id":"Po6ZPi4hphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"b0JNsNcRphqO"}},{"cell_type":"markdown","source":["**Marketing and Promotion:**\n","\n","Use the popularity of \"The Lovely Bones\" as a key marketing asset. Promote it prominently on the platform and in marketing campaigns.\n","\n","**Recommendation Systems:**\n","\n","Incorporate the high rating and popularity data into recommendation algorithms to suggest similar books to users.\n","\n","**Content Acquisition:**\n","\n","Focus on acquiring and promoting books that are similar in genre, style, or theme to \"The Lovely Bones\" and other highly-rated books."],"metadata":{"id":"xvSq8iUTphqO"}},{"cell_type":"markdown","source":["#### Horizontal Bar plot - Top 20 book by rating count"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"code","source":["# Chart - 8 visualization code\n","# Calculate the rating count for each book\n","rating_counts = df['Book-Title'].value_counts().reset_index()\n","rating_counts.columns = ['Book-Title', 'Rating Count']\n","\n","# Get the top 20 books with the highest rating counts\n","top_20_books = rating_counts.head(20)\n","\n","# Plot the rating counts\n","plt.figure(figsize=(14, 8))\n","plt.barh(top_20_books['Book-Title'], top_20_books['Rating Count'], color='skyblue')\n","plt.xlabel('Rating Count')\n","plt.ylabel('Book Title')\n","plt.title('Top 20 Most Popular Books by Rating Count')\n","plt.gca().invert_yaxis()  # Invert y-axis to have the highest rating count at the top\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"jj7wYXLtphqO"}},{"cell_type":"markdown","source":["If categories or labels are long (e.g., book titles), a horizontal bar plot makes it easier to display these labels without overlapping or truncating them."],"metadata":{"id":"Ob8u6rCTphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"eZrbJ2SmphqO"}},{"cell_type":"markdown","source":["**Observation:**\n","\n","\"The Lovely Bones: A Novel\" received over 700 ratings.\n","\n","\"Wild Animus\" received nearly 600 ratings.\n","\n","\"The Da Vinci Code\" received around 500 ratings.\n","\n","\"The Secret Life of Bees\" received around 400 ratings.\n","\n","\n","**High Engagement with Specific Titles:**\n","\n","**Observation:** These books have received a significant number of ratings, indicating high user engagement with these titles.\n","\n","**Insight:** The high rating counts suggest these books are popular and widely read among users on the platform. These titles likely resonate well with a broad audience, making them key assets for the platform.\n","\n","**Marketing and Promotional Strategies:**\n","\n","**Observation:** The popularity of these books can be leveraged in marketing campaigns.\n","\n","**Insight:** Featuring these books prominently in marketing materials, newsletters, and on the homepage can attract more users. Highlighting these popular books can also encourage users to engage more with the platform, leading to increased traffic and sales."],"metadata":{"id":"mZtgC_hjphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"rFu4xreNphqO"}},{"cell_type":"markdown","source":["**Increased User Engagement:**\n","\n","Action: Use these popular books to enhance user engagement by recommending similar titles and creating themed collections around these books.\n","\n","**Enhanced Marketing Strategies:**\n","\n","Action: Highlight these popular books in marketing campaigns, emails, and social media promotions.\n","\n","**Improved Recommendation Algorithms:**\n","\n","Action: Integrate the popularity of these books into recommendation algorithms to suggest similar books to users."],"metadata":{"id":"ey_0qi68phqO"}},{"cell_type":"markdown","source":["#### Horizantal Bar Plot - Top 10 Popular Authors"],"metadata":{"id":"YJ55k-q6phqO"}},{"cell_type":"code","source":["# Chart - 9 visualization code\n","# Calculate the rating count for each author\n","author_rating_counts = df.groupby('Book-Author')['Book-Rating'].count().reset_index()\n","author_rating_counts.columns = ['Book-Author', 'Rating Count']\n","\n","# Get the top 10 authors with the highest rating counts\n","top_10_authors = author_rating_counts.sort_values(by='Rating Count', ascending=False).head(10)\n","\n","# Plot the rating counts\n","plt.figure(figsize=(12, 8))\n","plt.barh(top_10_authors['Book-Author'], top_10_authors['Rating Count'], color='lightgreen')\n","plt.xlabel('Rating Count')\n","plt.ylabel('Author')\n","plt.title('Top 10 Most Popular Authors by Rating Count')\n","plt.gca().invert_yaxis()  # Invert y-axis to have the most popular authors at the top\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["If categories or labels are long (e.g., Book Author), a horizontal bar plot makes it easier to display these labels without overlapping or truncating them"],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["**Observation:**\n","\n","**Stephen King:** Over 4,000 rating count.\n","\n","**Nora Roberts:** Around 3,000 rating count.\n","\n","**John Grisham:** More than 2,000 rating count.\n","\n","**James Patterson:** More than 2,000 rating count.\n","\n","**J.K. Rowling:** Around 2,000 rating count.\n","\n","**High Popularity of Certain Authors:**\n","\n","**Observation:** Stephen King, Nora Roberts, John Grisham, James Patterson, and J.K. Rowling are some of the most popular authors on the platform, with Stephen King leading by a significant margin.\n","\n","**Insight:** These authors have a strong fan base and their books are highly engaging for users. Their popularity suggests that they are key figures in the reading community and drive significant traffic to the platform.\n","\n","**Opportunities for Targeted Marketing:**\n","\n","**Observation:** The high rating counts for these authors indicate that their books are widely read and reviewed.\n","\n","**Insight:** Marketing campaigns featuring these authors' books are likely to resonate with a broad audience. Promoting new releases, special collections, or discounts on books by these authors could lead to increased user engagement and sales."],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["**Increased User Engagement:**\n","\n","Action: Feature these popular authors prominently on the platform, in newsletters, and on social media. Highlight their most popular books and any new releases.\n","\n","**Boosted Sales and Traffic:**\n","\n","Action: Run targeted marketing campaigns focused on these authors, including promotions, discounts, and bundles of their books."],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["#### Word Cloud - Most frequent words in Book Titles"],"metadata":{"id":"U2RJ9gkRphqQ"}},{"cell_type":"code","source":["# Chart - 10 visualization code\n","# Create a single string of all book titles\n","text = ' '.join(df['Book-Title'].values)\n","\n","# Generate the word cloud\n","wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n","\n","# Display the word cloud\n","plt.figure(figsize=(10, 6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"GM7a4YP4phqQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"1M8mcRywphqQ"}},{"cell_type":"markdown","source":["A word cloud chart is a popular visualization technique that displays the frequency of words in a Book Title, with the size of each word indicating its frequency or importance."],"metadata":{"id":"8agQvks0phqQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"tgIPom80phqQ"}},{"cell_type":"markdown","source":["**Dominance of Fiction:**\n","\n","**Observation:** The word \"Novel\" being the largest suggests that the majority of books in dataset are fictional works.\n","\n","**Insight:** This indicates that fiction is the dominant genre on platform. The emphasis on novels suggests a strong user preference for this type of content.\n","\n","**Emphasis on Emotional and Relatable Themes:**\n","\n","**Observation:** Words like \"life,\" \"love,\" \"heart,\" and \"mysterious\" indicate that books dealing with emotional, relatable, and intriguing themes are popular.\n","\n","**Insight:** These themes resonate with audience, highlighting the types of narratives that engage users the most.\n","\n","**Specific Interests in \"Harry Potter\":**\n","\n","**Observation:** The prominence of \"Harry Potter\" suggests a strong interest in this specific series.\n","\n","**Insight:** The popularity of \"Harry Potter\" indicates a significant user interest in fantasy and young adult fiction."],"metadata":{"id":"Qp13pnNzphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"JMzcOPDDphqR"}},{"cell_type":"markdown","source":["**Dominance of Fiction:**\n","\n","**Business Impact:** To capitalize on this insight, we can focus on expanding fiction catalog, ensuring a diverse range of novels to cater to audience's preferences.\n","\n","**Emphasis on Emotional and Relatable Themes:**\n","\n","**Business Impact:** we can use this information to curate and promote books that emphasize these themes(**Words like \"life,\" \"love,\" \"heart,\" and \"mysterious\"**). Creating themed collections around these keywords could attract more users and enhance engagement.\n","\n","**Specific Interests in \"Harry Potter\":**\n","\n","**Business Impact:** we can create special promotions around the \"Harry Potter\" series, or similar fantasy books."],"metadata":{"id":"R4Ka1PC2phqR"}},{"cell_type":"markdown","source":["#### **Bubble Chart of Author Popularity**"],"metadata":{"id":"x-EpHcCOp1ci"}},{"cell_type":"code","source":["# Chart - 11 visualization code\n","# Calculate rating count and average rating for each author\n","author_stats = df.groupby('Book-Author')['Book-Rating'].agg(['mean', 'count']).reset_index()\n","\n","# Plot the bubble chart\n","plt.figure(figsize=(10, 6))\n","plt.scatter(author_stats['count'], author_stats['mean'], s=author_stats['count'], alpha=0.5)\n","plt.title('Bubble Chart of Author Popularity')\n","plt.xlabel('Rating Count')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"mAQTIvtqp1cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"X_VqEhTip1ck"}},{"cell_type":"markdown","source":["A bubble chart is a type of data visualization that extends the concept of a scatter plot by adding a third dimension, typically represented by the size of the bubbles. It is particularly useful in cases where you want to visualize the relationships between three variables in a single chart."],"metadata":{"id":"-vsMzt_np1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"8zGJKyg5p1ck"}},{"cell_type":"markdown","source":["**Observation:** Most authors have average ratings between 6 and 10, suggesting that readers generally rate books favorably.\n","\n","**Insight:** The broad range of average ratings within this band indicates that users are mostly satisfied with the books they read. This positive reception could mean that the platform is successful in curating content that resonates well with its audience.\n","\n"],"metadata":{"id":"ZYdMsrqVp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"PVzmfK_Ep1ck"}},{"cell_type":"markdown","source":["**Business Impact:** This insight confirms that the platform is maintaining a good selection of books that meet user expectations. Continued focus on acquiring and promoting highly-rated books will likely maintain or improve user satisfaction and engagement."],"metadata":{"id":"druuKYZpp1ck"}},{"cell_type":"markdown","source":["#### Chart - 12 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","\n","# Calculate the correlation matrix\n","corr_matrix = df.corr(numeric_only = True)\n","\n","# Plot the heatmap\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n","plt.title('Correlation Heatmap of Features')\n","plt.show()"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["A correlation heatmap is a visualization that displays the correlation matrix between multiple variables in a dataset. Correlation measures the strength and direction of the relationship between two variables, typically ranging from -1 (perfect negative correlation) to +1 (perfect positive correlation), with 0 indicating no correlation."],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["**Correlation Insights:**\n","\n","**Book Rating and Age:** A correlation of 0.03 suggests a very weak positive relationship. This means that age does not significantly influence book ratings.\n","\n","**Book Rating and Year of Publication:** A correlation of -0.01 indicates an almost negligible negative relationship. Thus, the publication year has a minimal impact on book ratings.\n","\n","**Book Rating and Book Age:** A correlation of 0.01 implies a very weak positive relationship. Book age (time since publication) does not significantly impact ratings.\n","\n","**Age and Year of Publication:** A correlation of 0.02 shows a very weak positive relationship between age and publication year. Age does not significantly impact the year a book was published.\n","\n","**Age and Book Age:** A correlation of -0.02 indicates a very weak negative relationship. Age has minimal effect on book age."],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["#### Chart - 13 - Pair Plot"],"metadata":{"id":"q29F0dvdveiT"}},{"cell_type":"code","source":["# Pair Plot visualization code\n","\n","# Create pair plot\n","sns.pairplot(df)\n","\n","# Show plot\n","plt.show()"],"metadata":{"id":"o58-TEIhveiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"EXh0U9oCveiU"}},{"cell_type":"markdown","source":["Pair plots help in visualizing the relationships between each pair of variables. This makes it easier to identify any linear or non-linear correlations."],"metadata":{"id":"eMmPjTByveiU"}},{"cell_type":"markdown","source":["\n","##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"22aHeOlLveiV"}},{"cell_type":"markdown","source":["**Plot - Book-Rating Vs. Age**\n","\n","Insight: The fact that users across all age groups have given ratings from 1 to 10 suggests that the books available on the platform have a broad appeal, catering to diverse age groups.\n","\n","**Plot - Book-Rating Vs. Book Age**\n","\n","**Books Less Than 20 Years Old:**\n","\n","Observation: These books have ratings from a limited number of users.\n","\n","Insight: This could indicate that newer books are either not as widely discovered or not as extensively reviewed by users on the platform. It may also suggest that these books are still building their reputation and readership.\n","\n","**Books Aged 20 to 100 Years:**\n","\n","Observation: These books received ratings from many users, covering the full spectrum of ratings from 1 to 10.\n","\n","Insight: This indicates a strong interest and engagement with books that fall within this age range. It suggests that these books are well-established and have a broad appeal across the user base.\n","\n","**Books More Than 100 Years Old:**\n","\n","Observation: These books predominantly received high ratings, typically between 5 and 10. But these books have ratings from a few users.\n","\n","Insight: This suggests that very old books, likely classics or well-regarded historical works, are highly valued by users. These books may have stood the test of time and are appreciated for their enduring quality and significance.\n","\n","**Plot - Year of Publication Vs. Book Age:**\n","\n","plot suggests a perfect negative relationship, meaning that as the publication year increases, book age decreases proportionally. This indicates a consistent trend where newer books have a shorter age, which is expected."],"metadata":{"id":"uPQ8RGwHveiV"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["**Hypothesis 1:**\n","\n","**Statement:** \"Books by J.K. Rowling have a significantly higher average rating compared to books by Stephen King.\"\n","\n","**Null Hypothesis (H0):** The average rating of books by J.K. Rowling is equal to the average rating of books by Stephen King.\n","\n","**Alternative Hypothesis (H1):** The average rating of books by J.K. Rowling is higher than the average rating of books by Stephen King."],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","# Filter ratings for J.K. Rowling and Stephen King\n","jk_rowling_ratings = df[df['Book-Author'] == 'J.K. Rowling']['Book-Rating']\n","stephen_king_ratings = df[df['Book-Author'] == 'Stephen King']['Book-Rating']\n","\n","# Perform t-test (one-tailed, as we are testing if J.K. Rowling's ratings are higher)\n","t_stat, p_value = stats.ttest_ind(jk_rowling_ratings, stephen_king_ratings, alternative='greater')\n","\n","print(\"Hypothesis 1 - J.K. Rowling vs. Stephen King\")\n","print(f\"T-Statistic: {t_stat}, P-Value: {p_value}\")\n","\n","# Decision based on p-value\n","alpha = 0.05\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis: J.K. Rowling's books have significantly higher ratings than Stephen King's books.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: No significant difference in ratings between J.K. Rowling's and Stephen King's books.\")"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["Test Used: Independent t-test (one-tailed)"],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":["**Nature of Data:** We are comparing the average ratings of books from two different authors. The data consists of two independent samples (ratings for J.K. Rowling's books and ratings for Stephen King's books).\n","\n","**Test Purpose:** An independent t-test is used to determine whether there is a statistically significant difference between the means of two independent groups. In this case, we are testing if the mean rating of J.K. Rowling's books is significantly higher than that of Stephen King's books.\n","\n","**One-Tailed Test:** Since we are specifically interested in whether J.K. Rowling's average ratings are higher (not just different), a one-tailed test is appropriate."],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["**Hypothesis 2:**\n","\n","**Statement:** \"Books published after the year 2000 receive higher ratings compared to books published before 2000.\"\n","\n","**Null Hypothesis (H0):** The average rating of books published after 2000 is equal to or less than the average rating of books published before 2000.\n","\n","**Alternative Hypothesis (H1):** The average rating of books published after 2000 is higher than the average rating of books published before 2000."],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","# Filter ratings for books published before and after 2000\n","ratings_before_2000 = df[df['Year-Of-Publication'] < 2000]['Book-Rating']\n","ratings_after_2000 = df[df['Year-Of-Publication'] >= 2000]['Book-Rating']\n","\n","# Perform t-test (one-tailed, as we are testing if ratings after 2000 are higher)\n","t_stat, p_value = stats.ttest_ind(ratings_after_2000, ratings_before_2000, alternative='greater')\n","\n","print(\"\\nHypothesis 2 - Books Published After 2000 vs. Before 2000\")\n","print(f\"T-Statistic: {t_stat}, P-Value: {p_value}\")\n","\n","# Decision based on p-value\n","alpha = 0.05\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis: Books published after 2000 have significantly higher ratings.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: No significant difference in ratings between books published before and after 2000.\")"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"markdown","source":["Test Used: Independent t-test (one-tailed)"],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["**Nature of Data:** We are comparing the average ratings of books published before and after 2000. These are two independent groups.\n","\n","**Test Purpose:** The independent t-test is again suitable here to compare the means of two independent groups (books published before 2000 vs. books published after 2000).\n","\n","**One-Tailed Test:** We hypothesize that books published after 2000 are rated higher, so a one-tailed test is used to see if the mean rating post-2000 is significantly greater than pre-2000."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["**Hypothesis 3:**\n","\n","**Statement:** \"Books with more than 500 ratings have a different average rating compared to books with fewer than 500 ratings.\"\n","\n","**Null Hypothesis (H0):** The average rating of books with more than 500 ratings is equal to the average rating of books with fewer than 500 ratings.\n","\n","**Alternative Hypothesis (H1):** The average rating of books with more than 500 ratings is different from the average rating of books with fewer than 500 ratings."],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","# Calculate rating counts for each book\n","rating_counts = df['Book-Title'].value_counts()\n","\n","# Filter books with more than 500 ratings and fewer than 500 ratings\n","popular_books = df[df['Book-Title'].isin(rating_counts[rating_counts > 500].index)]['Book-Rating']\n","less_popular_books = df[df['Book-Title'].isin(rating_counts[rating_counts <= 500].index)]['Book-Rating']\n","\n","# Perform t-test (two-tailed, as we are testing if ratings are different)\n","t_stat, p_value = stats.ttest_ind(popular_books, less_popular_books)\n","\n","print(\"\\nHypothesis 3 - Books with More vs. Fewer Than 500 Ratings\")\n","print(f\"T-Statistic: {t_stat}, P-Value: {p_value}\")\n","\n","# Decision based on p-value\n","alpha = 0.05\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis: Books with more than 500 ratings have a significantly different average rating.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: No significant difference in ratings between books with more and fewer than 500 ratings.\")"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":["Test Used: Independent t-test (two-tailed)"],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["**Nature of Data:** We are comparing the average ratings of two groups of books—those with more than 500 ratings and those with fewer than 500 ratings.\n","\n","**Test Purpose:** The independent t-test is suitable for comparing the means of two independent groups (high-rating-count books vs. low-rating-count books).\n","\n","**Two-Tailed Test:** Here, we are interested in any significant difference in average ratings, whether higher or lower, so a two-tailed test is appropriate.\n"],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["Independent t-test: This test is chosen for all hypotheses because we are comparing the means of two independent groups in each case.\n","\n","One-Tailed vs. Two-Tailed: The choice between one-tailed and two-tailed tests depends on whether we have a directional hypothesis (expecting one group to have higher/lower ratings) or a non-directional hypothesis (expecting any difference between groups).\n","\n","Why Not Use Other Tests?\n","Paired t-test: Not appropriate here since we are not comparing two related groups (e.g., before-and-after measurements on the same subjects).\n","\n","ANOVA: Could be used if we were comparing more than two groups, but since we are only comparing two groups in each case, the t-test is more straightforward.\n","\n","Mann-Whitney U test: This non-parametric alternative to the t-test could be used if the data were heavily non-normal, but the t-test is preferred for normally distributed data or when sample sizes are large enough for the Central Limit Theorem to apply."],"metadata":{"id":"cxnLaG5IJmYs"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","df.isnull().sum()"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["I have handled missing value already.\n","Which missing value imputation techniques have I used and why did I use those techniques?\n","\n","**Explaination:**\n","\n","**Book Title column - Simply dropped rows**\n","\n","Given that the book name is crucial for recommendations and understanding user preferences, it makes sense to drop entries where the book name is missing. This ensures that recommendation system is based on complete and meaningful data.\n","\n","**Age column - Median Imputation**\n","\n","Given that the \"Age\" column is crucial for your recommendation system and the distribution appears nearly normal after capping outliers, using median imputation for missing values is a suitable approach."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Take a random subset of 30,000 rows\n","subset_data = df.sample(n=30000, random_state=42)\n","subset_data = subset_data.reset_index(drop=True)"],"metadata":{"id":"Hpr2k1-BKuE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the LabelEncoder\n","le = LabelEncoder()\n","\n","# Perform label encoding on the 'ISBN' column\n","subset_data['ISBN_encoded'] = le.fit_transform(subset_data['ISBN'])"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["**Encoding technique used - Label Encoding**\n","\n","Why?\n","\n","**Uniqueness Representation**\n","\n","Each **ISBN** is unique: Label Encoding allows you to convert each unique ISBN into a unique integer, which preserves the uniqueness of the identifier. This is important in collaborative filtering, where each item (book) needs to be uniquely represented in the model.\n","\n","**Compact Representation:**\n","\n","Label Encoding is more memory-efficient compared to One-Hot Encoding, especially when dealing with high-cardinality features like ISBN(book id). It maps each unique ISBN to a single integer, keeping the data size manageable without introducing additional dimensions.\n","\n","**Preserving Relationships**\n","\n","Direct Mapping: Unlike One-Hot Encoding, which creates additional columns for each category, Label Encoding maintains a one-to-one mapping between the original ISBN and the encoded integer. This direct mapping is useful when the focus is on identifying unique entities rather than understanding relationships between them."],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["### 3. Textual Data Preprocessing\n","(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"],"metadata":{"id":"Iwf50b-R2tYG"}},{"cell_type":"markdown","source":["#### 1. Expand Contraction"],"metadata":{"id":"GMQiZwjn3iu7"}},{"cell_type":"code","source":["# Combine text features\n","subset_data['Combined Text'] = subset_data['Book-Title'] + ' ' + subset_data['Publisher'] + ' ' + subset_data['Book-Author']"],"metadata":{"id":"4bP-_bAwxTIb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Lower Casing"],"metadata":{"id":"WVIkgGqN3qsr"}},{"cell_type":"code","source":["# Lower Casing\n","subset_data['Combined Text'] = subset_data['Combined Text'].str.lower()"],"metadata":{"id":"88JnJ1jN3w7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Removing Punctuations"],"metadata":{"id":"XkPnILGE3zoT"}},{"cell_type":"code","source":["# Remove Punctuations\n","# Remove punctuation from 'book_title' column\n","subset_data['Combined Text'] = subset_data['Combined Text'].str.replace(f'[{string.punctuation}]', '', regex=True)"],"metadata":{"id":"vqbBqNaA33c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. Removing words and digits contain digits."],"metadata":{"id":"Hlsf0x5436Go"}},{"cell_type":"code","source":["# Remove words and digits contain digits\n","# Define a function to remove words containing digits\n","def remove_words_with_digits(text):\n","    # Use regex to match words with digits and remove them\n","    return ' '.join(word for word in text.split() if not re.search(r'\\d', word))\n","\n","# Apply the function to the 'book_title' column\n","subset_data['Combined Text'] = subset_data['Combined Text'].apply(remove_words_with_digits)"],"metadata":{"id":"2sxKgKxu4Ip3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Removing Stopwords & Removing White spaces"],"metadata":{"id":"mT9DMSJo4nBL"}},{"cell_type":"code","source":["# Remove Stopwords\n","# Get the list of English stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","# Function to remove stopwords\n","def remove_stopwords(text):\n","    return ' '.join(word for word in text.split() if word.lower() not in stop_words)\n","\n","# Apply the function to the 'book_title' column\n","subset_data['Combined Text'] = subset_data['Combined Text'].apply(remove_stopwords)"],"metadata":{"id":"T2LSJh154s8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove White spaces\n","# Replace multiple spaces with a single space\n","subset_data['Combined Text'] = subset_data['Combined Text'].str.replace('\\s+', ' ', regex=True).str.strip()"],"metadata":{"id":"EgLJGffy4vm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 6. Tokenization"],"metadata":{"id":"OeJFEK0N496M"}},{"cell_type":"code","source":["# Tokenization\n","# Define a function for tokenization\n","def tokenize_text(text):\n","    return word_tokenize(text)\n","\n","# Apply the function to the 'book_title' column\n","subset_data['Combined Text Token'] = subset_data['Combined Text'].apply(tokenize_text)"],"metadata":{"id":"ijx1rUOS5CUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 7. Text Normalization"],"metadata":{"id":"9ExmJH0g5HBk"}},{"cell_type":"code","source":["# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n","# Initialize lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# Define a function for lemmatization\n","def lemmatize_text(text):\n","    tokens = word_tokenize(text)\n","    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","    return ' '.join(lemmatized_tokens)\n","\n","# Apply the function to the 'book_title' column\n","subset_data['Combined Text lemmatized'] = subset_data['Combined Text'].apply(lemmatize_text)"],"metadata":{"id":"AIJ1a-Zc5PY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text normalization technique have you used and why?"],"metadata":{"id":"cJNqERVU536h"}},{"cell_type":"markdown","source":["Lemmatization is the process of reducing words to their base or root form. This is different from stemming, which cuts off prefixes or suffixes to get a root form. Lemmatization ensures that the base form is a valid word in the language."],"metadata":{"id":"Z9jKVxE06BC1"}},{"cell_type":"markdown","source":["#### 8. Text Vectorization"],"metadata":{"id":"T0VqWOYE6DLQ"}},{"cell_type":"code","source":["# Vectorizing Text\n","# Initialize TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","\n","# Fit and transform the 'book_title' column\n","tfidf_matrix = tfidf_vectorizer.fit_transform(subset_data['Combined Text lemmatized'])"],"metadata":{"id":"yBRtdhth6JDE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["subset_data.shape"],"metadata":{"id":"NfrAFtehEbOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df = df.drop(['Combined Text', 'Combined Text Token', 'Combined Text lemmatized'], axis=1)\n","subset_data = subset_data.drop(['Combined Text', 'Combined Text Token', 'Combined Text lemmatized'], axis=1)"],"metadata":{"id":"jQbpDz57uHRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text vectorization technique have you used and why?"],"metadata":{"id":"qBMux9mC6MCf"}},{"cell_type":"markdown","source":["TF-IDF is used for vectorizing text data like combine text because it effectively captures the importance of terms, reduces the impact of common words, improves feature representation, and facilitates accurate document similarity measurements."],"metadata":{"id":"su2EnbCh6UKQ"}},{"cell_type":"markdown","source":["### 4. Feature Manipulation & Selection"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"markdown","source":["Feature manipulation has handled in text data preprocessing already"],"metadata":{"id":"cIzJIzDTDtGI"}},{"cell_type":"markdown","source":["#### 2. Feature Selection"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"markdown","source":["##### Which all features you found important and why?"],"metadata":{"id":"rAdphbQ9Bhjc"}},{"cell_type":"markdown","source":["**Key Features for Collaborative Filtering**\n","\n","**User-ID:**\n","\n","Importance: Essential.\n","\n","Role: Represents the user in the recommendation system. Collaborative filtering models rely heavily on identifying users and finding similar users (User-Based Collaborative Filtering) or determining which items are most similar based on user interactions (Item-Based Collaborative Filtering).\n","\n","**ISBN_encoded (Book-ID):**\n","\n","Importance: Essential.\n","\n","Role: Represents the item (book) in the recommendation system. It is used to track which books have been rated by users and to identify similar items.\n","\n","**Book-Rating:**\n","\n","Importance: Essential.\n","Role: The actual rating given by users to books. This feature is the core of collaborative filtering since it captures user preferences. Ratings are used to calculate similarities between users or items.\n","\n","**Key Features for Content-Based Filtering:**\n","\n","**Book-Title:**\n","\n","Importance: High.\n","\n","Role: Although book titles themselves might not directly convey content, they can be used in natural language processing (NLP) tasks to extract keywords, or be included in a string similarity comparison. They might be more useful in combination with other text features like descriptions.\n","\n","**Book-Author:**\n","\n","Importance: High.\n","\n","Role: Author names can be indicative of the writing style or genre, which can be important for users who prefer books by specific authors. This feature can be used to suggest other books by the same author or similar authors.\n","\n","**Publisher:**\n","\n","Importance: Moderate.\n","\n","Role: Like the author, the publisher might be less critical but can still provide context, especially if certain publishers specialize in specific genres or types of books."],"metadata":{"id":"fGgaEstsBnaf"}},{"cell_type":"markdown","source":["### 5. Data Transformation"],"metadata":{"id":"TNVZ9zx19K6k"}},{"cell_type":"markdown","source":["#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"],"metadata":{"id":"nqoHp30x9hH9"}},{"cell_type":"markdown","source":["No need"],"metadata":{"id":"Dv-bZBxnFcjI"}},{"cell_type":"code","source":["# Transform Your data"],"metadata":{"id":"I6quWQ1T9rtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Data Scaling"],"metadata":{"id":"rMDnDkt2B6du"}},{"cell_type":"markdown","source":["No need"],"metadata":{"id":"GnjeTy-0FuSY"}},{"cell_type":"code","source":["# Scaling your data"],"metadata":{"id":"dL9LWpySC6x_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which method have you used to scale you data and why?"],"metadata":{"id":"yiiVWRdJDDil"}},{"cell_type":"markdown","source":["### 7. Dimesionality Reduction"],"metadata":{"id":"1UUpS68QDMuG"}},{"cell_type":"markdown","source":["##### Do you think that dimensionality reduction is needed? Explain Why?"],"metadata":{"id":"kexQrXU-DjzY"}},{"cell_type":"code","source":["# Dimensionality Reduction (If needed)"],"metadata":{"id":"kQfvxBBHDvCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"],"metadata":{"id":"T5CmagL3EC8N"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"ZKr75IDuEM7t"}},{"cell_type":"markdown","source":["### 8. Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["# Split your data to train and test. Choose Splitting ratio wisely.\n","# Define the feature columns and the target column\n","feature_columns = ['User-ID','Book-Title','Book-Author','Year-Of-Publication','Publisher','ISBN_encoded']\n","target_column = 'Book-Rating'  # The column you want to predict\n","\n","# Split the data into features (X) and target (y)\n","X = subset_data[feature_columns]\n","y = subset_data[target_column]\n","\n","# Split into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"0CTyd2UwEyNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What data splitting ratio have you used and why?"],"metadata":{"id":"qjKvONjwE8ra"}},{"cell_type":"markdown","source":["**80:20 Split:**\n","\n","80% Training Data: Used for training the model.\n","20% Test Data: Used for evaluating the model's performance on unseen data.\n","\n","**Why Use an 80:20 Split?**\n","\n","**Sufficient Training Data:**\n","\n","80%  of the data being used for training provides the model with enough data to learn the patterns and relationships in the dataset. This is particularly important for recommendation systems, where understanding user preferences and item features requires a substantial amount of data.\n","\n","**Reliable Evaluation:**\n","\n","20% of the data being held out for testing allows for a reliable evaluation of the model's performance. This ensures that the model's accuracy, precision, recall, and other metrics reflect its ability to generalize to new, unseen data.\n","\n","**Preventing Overfitting:**\n","\n","By holding out a portion of the data for testing, you can detect overfitting, where the model might perform well on the training data but poorly on unseen data. This is crucial for building robust recommendation systems that work well in real-world scenarios.\n","\n","**Resource Considerations:**\n","\n","An 80:20 split is a good balance between giving the model enough data to learn and having enough data to evaluate the model's performance."],"metadata":{"id":"Y2lJ8cobFDb_"}},{"cell_type":"markdown","source":["### 9. Handling Imbalanced Dataset"],"metadata":{"id":"P1XJ9OREExlT"}},{"cell_type":"markdown","source":["##### Do you think the dataset is imbalanced? Explain Why."],"metadata":{"id":"VFOzZv6IFROw"}},{"cell_type":"markdown","source":["No"],"metadata":{"id":"GeKDIv7pFgcC"}},{"cell_type":"code","source":["# Handling Imbalanced Dataset (If needed)"],"metadata":{"id":"nQsRhhZLFiDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"],"metadata":{"id":"TIqpNgepFxVj"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"code","source":["# Step 1: Combine X_train and y_train into a single DataFrame\n","train_data = X_train.copy()\n","train_data['Book-Rating'] = y_train\n","\n","# Combine X_test and y_test similarly\n","test_data = X_test.copy()\n","test_data['Book-Rating'] = y_test\n","\n","# Step 2: Prepare the data for Surprise\n","# Define the rating scale (assuming ratings are between 1 and 10)\n","reader = Reader(rating_scale=(1, 10))\n","\n","# Load the training data into the Surprise dataset\n","trainset = Dataset.load_from_df(train_data[['User-ID', 'ISBN_encoded', 'Book-Rating']], reader).build_full_trainset()\n","\n","# Step 3: Train the Collaborative Filtering Model\n","# Use SVD (Singular Value Decomposition)\n","model = SVD()\n","model.fit(trainset)\n","\n","# Step 4: Evaluate the Model on the Test Set\n","# Create the testset for the Surprise model using the test data\n","testset = list(zip(X_test['User-ID'], X_test['ISBN_encoded'], y_test))\n","\n","# Generate predictions\n","predictions = model.test(testset)  # Evaluate the model performance\n","\n"],"metadata":{"id":"bA4UxvGhjTVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"markdown","source":["The model is user is (Singular Value Decomposition (SVD)."],"metadata":{"id":"2pg2scjSKE33"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Evaluate the model performance\n","rmse = accuracy.rmse(predictions)\n","print(f\"Collaborative Filtering RMSE: {rmse:.4f}\")\n","\n","# You can also explore other metrics, like MAE\n","mae = accuracy.mae(predictions)\n","print(f\"Collaborative Filtering MAE: {mae:.4f}\")\n","\n","# Step 1: Define a threshold for considering a prediction as a positive recommendation\n","threshold = 7  # This is a common threshold, but you can adjust based on your application\n","\n","# Extract true labels and predicted labels based on the threshold\n","y_true = [true_r >= threshold for (_, _, true_r, _, _) in predictions]\n","y_pred = [est >= threshold for (_, _, _, est, _) in predictions]\n","\n","# Calculate precision, recall, and F1 score\n","precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n","\n","print(f\"Tuned Collaborative Filtering Precision: {precision:.4f}\")\n","print(f\"Tuned Collaborative Filtering Recall: {recall:.4f}\")\n","print(f\"Tuned Collaborative Filtering F1 Score: {f1:.4f}\")\n","\n","# Step 2: Predict the rating for the book 'First to Fight' for a specific user\n","user_id = X_test['User-ID'].iloc[1]  # Replace with User-ID from your test set\n","isbn_encoded = 10057\n","book_title = 'First to Fight'\n","# Use the trained model (model) to predict the rating\n","predicted_rating = model.predict(user_id, isbn_encoded).est\n","print(f\"Predicted rating for user {user_id} on '{book_title}': {predicted_rating:.2f}\")"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"code","source":["# Combine X_train and y_train into a single DataFrame\n","train_data = X_train.copy()\n","train_data['Book-Rating'] = y_train\n","\n","# Prepare the data for Surprise\n","reader = Reader(rating_scale=(1, 10))\n","data = Dataset.load_from_df(train_data[['User-ID', 'ISBN_encoded', 'Book-Rating']], reader)\n","\n","# Define the parameter grid for SVD\n","param_grid = {\n","    'n_factors': [20, 50, 100, 150],  # Number of latent factors in the matrix factorization\n","    'lr_all': [0.002, 0.005, 0.01, 0.02],  # Learning rate for all parameters\n","    'reg_all': [0.02, 0.05, 0.1, 0.2]  # Regularization term for all parameters\n","}\n","\n","# Perform GridSearchCV to find the best hyperparameters\n","gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=-1)\n","gs.fit(data)\n","\n","# Get the best model based on RMSE\n","best_model = gs.best_estimator['rmse']\n","print(f\"Best RMSE Score: {gs.best_score['rmse']}\")\n","print(f\"Best Hyperparameters: {gs.best_params['rmse']}\")\n","\n","# Train the best model on the full training set\n","trainset = data.build_full_trainset()\n","best_model.fit(trainset)\n","\n","# Evaluate the model on the test set\n","testset = list(zip(X_test['User-ID'], X_test['ISBN_encoded'], y_test))\n","predictions = best_model.test(testset)"],"metadata":{"id":"2fpRjtD5mgTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Evaluate the model performance\n","rmse = accuracy.rmse(predictions)\n","print(f\"Collaborative Filtering RMSE: {rmse:.4f}\")\n","\n","# You can also explore other metrics, like MAE\n","mae = accuracy.mae(predictions)\n","print(f\"Collaborative Filtering MAE: {mae:.4f}\")\n","\n","# Step 1: Define a threshold for considering a prediction as a positive recommendation\n","threshold = 7  # This is a common threshold, but you can adjust based on your application\n","\n","# Extract true labels and predicted labels based on the threshold\n","y_true = [true_r >= threshold for (_, _, true_r, _, _) in predictions]\n","y_pred = [est >= threshold for (_, _, _, est, _) in predictions]\n","\n","# Calculate precision, recall, and F1 score\n","precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n","\n","print(f\"Tuned Collaborative Filtering Precision: {precision:.4f}\")\n","print(f\"Tuned Collaborative Filtering Recall: {recall:.4f}\")\n","print(f\"Tuned Collaborative Filtering F1 Score: {f1:.4f}\")\n","\n","# Step 2: Predict the rating for the book which have isbn encoded 13276 for a specific user\n","user_id = X_test['User-ID'].iloc[1]  # Replace with an actual User-ID from your test set\n","isbn_encoded = 10057\n","book_title = 'First to Fight'\n","\n","# Use the trained model (model) to predict the rating\n","predicted_rating = model.predict(user_id, isbn_encoded).est\n","print(f\"Predicted rating for user {user_id} on '{book_title}': {predicted_rating:.2f}\")"],"metadata":{"id":"YmzM_DRdYOba"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["Grid Search is a widely used hyperparameter optimization technique in machine learning. It systematically works through multiple combinations of parameter values, cross-validating as it goes to determine which combination provides the best model performance. Here's why Grid Search is commonly used."],"metadata":{"id":"negyGRa7fxKf"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"TfvqoZmBfxKf"}},{"cell_type":"markdown","source":["Yes, It sightly reduce the Root Mean Square Error and Mean Absolute Error value and increase the precision."],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["####Explain each evaluation metric's indication towards business and the business impact pf the ML model used."],"metadata":{"id":"bmKjuQ-FpsJ3"}},{"cell_type":"markdown","source":["**1. Root Mean Square Error (RMSE)**\n","\n","Indication:\n","\n","RMSE measures the average magnitude of the error between predicted and actual ratings, penalizing larger errors more heavily due to squaring the differences before averaging.\n","A lower RMSE indicates that the model’s predictions are closer to the actual ratings, meaning it’s more accurate in predicting user preferences.\n","\n","**Business Impact:**\n","\n","Customer Satisfaction: A model with a low RMSE is likely to recommend products (or books) that users truly enjoy, leading to higher customer satisfaction. If the model often predicts ratings that are far from the user's actual rating, it might suggest irrelevant or less-liked products, frustrating the user and potentially leading to churn.\n","\n","Sales & Revenue: More accurate predictions can drive higher engagement with recommended items, leading to increased sales and revenue. For instance, if a recommendation is accurate and the customer is satisfied with the suggestion, they are more likely to make a purchase.\n","\n","Trust in the Platform: Consistently accurate recommendations build user trust. Users are more likely to rely on and continue using a platform that consistently suggests relevant and satisfying options.\n","\n","**2. Mean Absolute Error (MAE)**\n","\n","Indication:\n","\n","MAE measures the average magnitude of errors in predictions, without considering the direction (i.e., it doesn’t penalize large errors as heavily as RMSE).\n","Like RMSE, a lower MAE indicates better model accuracy, but it provides a more straightforward interpretation as the average error in predicted ratings.\n","\n","**Business Impact:**\n","\n","User Experience: MAE gives an easy-to-understand metric for the average error in recommendations. If users frequently see recommendations that are close to their preferences, the overall user experience improves.\n","\n","Product Relevance: A low MAE ensures that the recommendations made by the model are generally relevant to the user’s tastes. This can increase the time users spend on the platform, exploring and interacting with more products.\n","\n","Cost Efficiency: Lower prediction errors reduce the likelihood of users being recommended items they won’t purchase, which can improve the efficiency of marketing spend and inventory management.\n","\n","**3. Precision**\n","\n","Indication:\n","\n","Precision measures the proportion of true positive recommendations (items the user liked) out of all items the model predicted as liked (recommended).\n","High precision means that when the model predicts an item as liked, it’s likely to be correct.\n","\n","**Business Impact:**\n","\n","Targeted Marketing: High precision ensures that marketing efforts, such as targeted ads or personalized emails, focus on products that users are likely to purchase, reducing wasted marketing resources.\n","\n","User Retention: Precise recommendations improve user satisfaction, reducing the risk of user churn. If users consistently see relevant recommendations, they are more likely to return to the platform.\n","Brand Loyalty: By consistently recommending products that users like, the brand builds loyalty, as users feel that the platform understands their needs and preferences.\n","\n","**4. Recall**\n","\n","Indication:\n","\n","Recall measures the proportion of true positive recommendations (items the user liked) out of all items that the user actually liked.\n","High recall means the model is good at identifying and recommending most of the items a user would like.\n","\n","**Business Impact:**\n","\n","Comprehensive Recommendations: High recall ensures that users are exposed to a wide range of products that fit their preferences, increasing the likelihood of discovery and purchase of additional items.\n","\n","Sales Uplift: By recommending more items that users are likely to enjoy, even if they haven't explicitly searched for them, recall can lead to additional sales, thus boosting revenue.\n","\n","Customer Discovery: Strong recall can help users discover new products that align with their tastes, potentially leading to increased customer satisfaction and loyalty as they find value in the platform's ability to suggest new favorites.\n","\n","**5. F1 Score**\n","\n","Indication:\n","\n","The F1 Score is the harmonic mean of precision and recall, providing a single metric that balances the trade-offs between the two. It’s particularly useful when you need to balance the importance of precision and recall.\n","A high F1 score indicates that the model performs well in both precision and recall, meaning it’s both accurate and comprehensive in its recommendations.\n","\n","**Business Impact:**\n","\n","Balanced Performance: A high F1 score ensures that the recommendation system is both precise (users see mostly relevant items) and has a wide coverage (users see most of the items they would like). This balance is critical for maintaining a positive user experience.\n","\n","Optimized Customer Engagement: By balancing precision and recall, the F1 score reflects the model’s ability to drive engagement without overwhelming users with too many irrelevant suggestions or missing potential opportunities to recommend good products.\n","\n","Strategic Decision-Making: Businesses can rely on the F1 score to understand the overall effectiveness of their recommendation systems, allowing them to make informed decisions about where to invest in further model improvements.\n","\n","**Overall Business Impact of the ML Model:**\n","\n","Increased Revenue: By improving the relevance and accuracy of recommendations, the model drives more purchases, thereby increasing revenue.\n","\n","Enhanced Customer Experience: Accurate and comprehensive recommendations improve user satisfaction, leading to higher retention rates and brand loyalty.\n","\n","Efficient Resource Allocation: Precision ensures that marketing and promotional efforts are well-targeted, reducing waste and improving ROI.\n","\n","Competitive Advantage: A robust recommendation system can set a business apart from its competitors, making it a preferred platform for users seeking personalized experiences."],"metadata":{"id":"BDKtOrBQpsJ3"}},{"cell_type":"markdown","source":["### ML Model - 2"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"code","source":["# Convert the sparse matrix to a dense format and cast to float32 for Faiss\n","tfidf_dense = tfidf_matrix.astype(np.float32).toarray()\n","\n","# Initialize the Faiss index\n","dimension = tfidf_dense.shape[1]\n","index = faiss.IndexFlatL2(dimension)\n","\n","# Add the dense vectors to the Faiss index\n","index.add(tfidf_dense)"],"metadata":{"id":"7PIG0dU2TM6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to get content-based recommendations using Faiss\n","def get_faiss_recommendations(dataset, title, n=10):\n","    # Check if the title exists in the dataset\n","    if title not in dataset['Book-Title'].values:\n","        print(f\"Title '{title}' not found in the dataset.\")\n","        return None\n","\n","    # Get the index of the book that matches the title\n","    idx = dataset[dataset['Book-Title'] == title].index[0]\n","\n","    # Get the query vector for the book\n","    query_vector = tfidf_dense[idx].reshape(1, -1)  # Reshape for Faiss\n","\n","    # Search for the most similar items\n","    distances, indices = index.search(query_vector, n+1)  # n+1 to skip the first one (itself)\n","\n","    # Get the top similar books, excluding the queried book itself\n","    similar_books = dataset.iloc[indices[0][1:]][['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']]\n","\n","    return similar_books\n","\n","# Example usage\n","recommended_books = get_faiss_recommendations(subset_data,'First to Fight')\n","if recommended_books is not None:\n","    print(recommended_books)"],"metadata":{"id":"tuq_wHglD5V8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"-jK_YjpMpsJ2"}},{"cell_type":"code","source":["# Define the hyperparameter grid\n","param_grid = {\n","    'index_type': ['FlatL2', 'IVF'],  # Types of FAISS index to try\n","    'nlist': [50, 100, 200],          # Number of clusters (for IVF)\n","    'nprobe': [5, 10, 20]             # Number of clusters to visit during search (for IVF)\n","}\n","\n","# Initialize variables to track the best configuration\n","best_ap = 0\n","best_params = None\n","\n","# Function to evaluate FAISS configuration using Average Precision (AP)\n","def evaluate_faiss(index, validation_titles, n=10):\n","    ap_scores = []\n","    for title in validation_titles:\n","        recommendations = get_faiss_recommendations(subset_data,title, n)\n","        if recommendations is not None:\n","            # Assume that true relevance is the first item for simplification\n","            true_relevance = np.zeros(n)\n","            true_relevance[0] = 1  # Assume the first recommended item is the correct one\n","            ap_scores.append(average_precision_score(true_relevance, np.ones(n)))\n","    return np.mean(ap_scores)\n","\n","# Perform the grid search manually\n","for index_type in param_grid['index_type']:\n","    for nlist in param_grid['nlist']:\n","        for nprobe in param_grid['nprobe']:\n","            print(f\"Evaluating index_type={index_type}, nlist={nlist}, nprobe={nprobe}\")\n","\n","            # Create and train FAISS index\n","            if index_type == 'IVF':\n","                quantizer = faiss.IndexFlatL2(tfidf_dense.shape[1])\n","                index = faiss.IndexIVFFlat(quantizer, tfidf_dense.shape[1], nlist)\n","                index.train(tfidf_dense)\n","                index.nprobe = nprobe  # Set the number of probes for IVF index\n","            else:\n","                index = faiss.IndexFlatL2(tfidf_dense.shape[1])\n","\n","            # Add the vectors to the index\n","            index.add(tfidf_dense)\n","\n","            # Evaluate this configuration\n","            validation_titles = subset_data['Book-Title'].sample(100, random_state=42).values\n","            ap_score = evaluate_faiss(index, validation_titles, n=10)\n","\n","            print(f\"AP Score: {ap_score:.4f}\")\n","\n","            # Update the best parameters if the current configuration is better\n","            if ap_score > best_ap:\n","                best_ap = ap_score\n","                best_params = {'index_type': index_type, 'nlist': nlist, 'nprobe': nprobe}\n","\n","print(f\"Best AP Score: {best_ap}\")\n","print(f\"Best Parameters: {best_params}\")\n","\n","# Once the best parameters are found, rebuild the final index with those parameters\n","if best_params['index_type'] == 'IVF':\n","    quantizer = faiss.IndexFlatL2(tfidf_dense.shape[1])\n","    final_index = faiss.IndexIVFFlat(quantizer, tfidf_dense.shape[1], best_params['nlist'])\n","    final_index.train(tfidf_dense)\n","    final_index.nprobe = best_params['nprobe']\n","else:\n","    final_index = faiss.IndexFlatL2(tfidf_dense.shape[1])\n","\n","final_index.add(tfidf_dense)\n","\n","# Update the function to use the final index\n","def get_faiss_recommendations(dataset,title, n=10):\n","    # Check if the title exists in the dataset\n","    if title not in dataset['Book-Title'].values:\n","        print(f\"Title '{title}' not found in the dataset.\")\n","        return None\n","\n","    # Get the index of the book that matches the title\n","    idx = dataset[dataset['Book-Title'] == title].index[0]\n","\n","    # Get the query vector for the book\n","    query_vector = tfidf_dense[idx].reshape(1, -1)\n","\n","    # Search for the most similar items\n","    distances, indices = final_index.search(query_vector, n+1)\n","\n","    # Get the top similar books, excluding the queried book itself\n","    similar_books = dataset.iloc[indices[0][1:]][['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']]\n","\n","    return similar_books\n","\n","# Example usage with the final tuned index\n","recommended_books = get_faiss_recommendations(subset_data,'First to Fight')\n","if recommended_books is not None:\n","    print(recommended_books)"],"metadata":{"id":"Dn0EOfS6psJ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"HAih1iBOpsJ2"}},{"cell_type":"markdown","source":["uses FAISS (Facebook AI Similarity Search) for content-based recommendations. FAISS is used to perform efficient similarity searches, typically in high-dimensional spaces like those generated by TF-IDF (Term Frequency-Inverse Document Frequency) vectors."],"metadata":{"id":"9kBgjYcdpsJ2"}},{"cell_type":"markdown","source":["### ML Model - 3"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"code","source":["# Function to get content-based recommendations using Faiss\n","def get_faiss_recommendations(dataset, title, n=10):\n","    # Check if the title exists in the dataset\n","    if title not in dataset['Book-Title'].values:\n","        print(f\"Title '{title}' not found in the dataset.\")\n","        return None\n","\n","    # Get the index of the book that matches the title\n","    idx = dataset[dataset['Book-Title'] == title].index[0]\n","\n","    # Get the query vector for the book\n","    query_vector = tfidf_dense[idx].reshape(1, -1)  # Reshape for Faiss\n","\n","    # Search for the most similar items\n","    distances, indices = index.search(query_vector, n+1)  # n+1 to skip the first one (itself)\n","\n","    # Get the top similar books, excluding the queried book itself\n","    similar_books = dataset.iloc[indices[0][1:]][['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']]\n","\n","    return similar_books\n","\n","# Example usage for content-based recommendations\n","recommended_books = get_faiss_recommendations(subset_data, 'First to Fight')\n","\n","# Step 2: Collaborative Filtering Setup\n","# Combine X_train and y_train into a single DataFrame\n","train_data = X_train.copy()\n","train_data['Book-Rating'] = y_train\n","\n","# Combine X_test and y_test similarly\n","test_data = X_test.copy()\n","test_data['Book-Rating'] = y_test\n","\n","# Step 3: Prepare the data for Surprise (Collaborative Filtering)\n","# Define the rating scale (assuming ratings are between 1 and 10)\n","reader = Reader(rating_scale=(1, 10))\n","\n","# Load the training data into the Surprise dataset\n","trainset = Dataset.load_from_df(train_data[['User-ID', 'ISBN_encoded', 'Book-Rating']], reader).build_full_trainset()\n","\n","# Train the Collaborative Filtering Model (SVD)\n","model = SVD()\n","model.fit(trainset)\n","\n","\n","# Example of Hybrid Recommendation\n","def get_hybrid_recommendations(user_id, title, n=10):\n","    # Collaborative Filtering: Predict the rating the user would give to the book\n","    try:\n","        collaborative_prediction = model.predict(user_id, title).est\n","    except:\n","        collaborative_prediction = None\n","\n","    # Content-Based Filtering: Get similar books using Faiss\n","    content_based_recommendations = get_faiss_recommendations(subset_data, title, n)\n","\n","    if content_based_recommendations is None:\n","        print(f\"No content-based recommendations found for '{title}'.\")\n","        return None\n","\n","    # Combine the results\n","    if collaborative_prediction is not None:\n","        # Add the collaborative filtering score to the content-based recommendations\n","        content_based_recommendations['Collaborative_Score'] = collaborative_prediction\n","\n","        # Sort the content-based recommendations by the collaborative score (if available)\n","        content_based_recommendations = content_based_recommendations.sort_values('Collaborative_Score', ascending=False)\n","\n","    return content_based_recommendations\n","\n","# Example usage with a specific user and book title for hybrid recommendations\n","user_id = X_test['User-ID'].iloc[1]  # Replace with an actual User-ID from your test set\n","book_title = 'First to Fight'  # Replace with an actual book title from your dataset\n","hybrid_recommendations = get_hybrid_recommendations(user_id, book_title, n=10)\n","\n","if hybrid_recommendations is not None:\n","    print(hybrid_recommendations)\n"],"metadata":{"id":"9XVZO_fsxkh0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"7AN1z2sKpx6M"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","# Step 4: Evaluate the Model on the Test Set\n","# Create the testset for the Surprise model using the test data\n","testset = list(zip(X_test['User-ID'], X_test['ISBN_encoded'], y_test))\n","\n","# Generate predictions\n","predictions = model.test(testset)  # Evaluate the model performance\n","rmse = accuracy.rmse(predictions)\n","print(f\"Collaborative Filtering RMSE: {rmse:.4f}\")"],"metadata":{"id":"xIY4lxxGpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"9PIHJqyupx6M"}},{"cell_type":"code","source":["# Function to get content-based recommendations using Faiss\n","def get_faiss_recommendations(dataset, title, n=10):\n","    if title not in dataset['Book-Title'].values:\n","        print(f\"Title '{title}' not found in the dataset.\")\n","        return None\n","\n","    idx = dataset[dataset['Book-Title'] == title].index[0]\n","    query_vector = tfidf_dense[idx].reshape(1, -1)\n","\n","    distances, indices = index.search(query_vector, n+1)\n","    similar_books = dataset.iloc[indices[0][1:]][['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication']]\n","\n","    return similar_books\n","\n","# Function to evaluate FAISS configuration using Average Precision (AP)\n","def evaluate_faiss(index, validation_titles, n=10):\n","    ap_scores = []\n","    for title in validation_titles:\n","        recommendations = get_faiss_recommendations(subset_data,title, n)\n","        if recommendations is not None:\n","            # Assume that true relevance is the first item for simplification\n","            true_relevance = np.zeros(n)\n","            true_relevance[0] = 1  # Assume the first recommended item is the correct one\n","            ap_scores.append(average_precision_score(true_relevance, np.ones(n)))\n","    return np.mean(ap_scores)\n","\n","# Step 2: Hyperparameter Tuning for Collaborative Filtering (SVD)\n","param_grid = {\n","    'n_factors': [20, 50, 100],\n","    'lr_all': [0.002, 0.005, 0.01],\n","    'reg_all': [0.02, 0.05, 0.1]\n","}\n","\n","gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=-1)\n","train_data = X_train.copy()\n","train_data['Book-Rating'] = y_train\n","reader = Reader(rating_scale=(1, 10))\n","data = Dataset.load_from_df(train_data[['User-ID', 'ISBN_encoded', 'Book-Rating']], reader)\n","gs.fit(data)\n","\n","best_svd = gs.best_estimator['rmse']\n","print(f\"Best SVD Parameters: {gs.best_params['rmse']}\")\n","print(f\"Best RMSE Score: {gs.best_score['rmse']}\")\n","\n","# Train the best SVD model on the full training set\n","trainset = data.build_full_trainset()\n","best_svd.fit(trainset)\n","\n","# Step 3: Hyperparameter Tuning for FAISS\n","param_grid_faiss = {\n","    'nlist': [50, 100, 200],\n","    'nprobe': [5, 10, 20]\n","}\n","\n","best_ap = 0\n","best_faiss_params = None\n","\n","for nlist in param_grid_faiss['nlist']:\n","    for nprobe in param_grid_faiss['nprobe']:\n","        index_ivf = faiss.IndexIVFFlat(faiss.IndexFlatL2(dimension), dimension, nlist)\n","        index_ivf.train(tfidf_dense)\n","        index_ivf.nprobe = nprobe\n","        index_ivf.add(tfidf_dense)\n","        # Evaluate this configuration\n","        validation_titles = subset_data['Book-Title'].sample(100, random_state=42).values\n","        ap_score = evaluate_faiss(index, validation_titles, n=10)\n","        #ap_score = evaluate_faiss(index_ivf, X_test, X_train, n=10)  # Custom evaluation function for MAP or Precision\n","        print(f\"nlist: {nlist}, nprobe: {nprobe}, AP Score: {ap_score:.4f}\")\n","\n","        if ap_score > best_ap:\n","            best_ap = ap_score\n","            best_faiss_params = {'nlist': nlist, 'nprobe': nprobe}\n","\n","print(f\"Best FAISS Parameters: {best_faiss_params}\")\n","print(f\"Best AP Score: {best_ap}\")\n","\n","# Use the best parameters for FAISS\n","index_ivf = faiss.IndexIVFFlat(faiss.IndexFlatL2(dimension), dimension, best_faiss_params['nlist'])\n","index_ivf.train(tfidf_dense)\n","index_ivf.nprobe = best_faiss_params['nprobe']\n","index_ivf.add(tfidf_dense)\n","\n","# Step 4: Hybrid Recommendation Function\n","def get_hybrid_recommendations(user_id, title, n=10):\n","    try:\n","        collaborative_prediction = best_svd.predict(user_id, title).est\n","    except:\n","        collaborative_prediction = None\n","\n","    content_based_recommendations = get_faiss_recommendations(subset_data, title, n)\n","    if content_based_recommendations is None:\n","        print(f\"No content-based recommendations found for '{title}'.\")\n","        return None\n","\n","    if collaborative_prediction is not None:\n","        content_based_recommendations['Collaborative_Score'] = collaborative_prediction\n","        content_based_recommendations = content_based_recommendations.sort_values('Collaborative_Score', ascending=False)\n","\n","    return content_based_recommendations\n","\n","# Example usage with a specific user and book title for hybrid recommendations\n","user_id = X_test['User-ID'].iloc[1]\n","book_title = 'First to Fight'\n","hybrid_recommendations = get_hybrid_recommendations(user_id, book_title, n=10)\n","\n","if hybrid_recommendations is not None:\n","    print(hybrid_recommendations)\n"],"metadata":{"id":"G988A7TvyL1o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"_-qAgymDpx6N"}},{"cell_type":"markdown","source":["Grid Search is a widely used hyperparameter optimization technique in machine learning. It systematically works through multiple combinations of parameter values, cross-validating as it goes to determine which combination provides the best model performance. Here's why Grid Search is commonly used and uses FAISS (Facebook AI Similarity Search) for content-based recommendations. FAISS is used to perform efficient similarity searches, typically in high-dimensional spaces like those generated by TF-IDF (Term Frequency-Inverse Document Frequency) vectors."],"metadata":{"id":"lQMffxkwpx6N"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"Z-hykwinpx6N"}},{"cell_type":"markdown","source":["The recent adjustments in the model have led to a slight improvement in the RMSE (Root Mean Square Error) value, which indicates that the prediction errors have decreased, resulting in more accurate predictions of book ratings. Additionally, these refinements have significantly enhanced the accuracy of book recommendations, ensuring that the suggested books better align with users' preferences."],"metadata":{"id":"MzVzZC6opx6N"}},{"cell_type":"markdown","source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"],"metadata":{"id":"h_CCil-SKHpo"}},{"cell_type":"markdown","source":["**1. Root Mean Square Error (RMSE):**\n","\n","Why it was chosen:\n"," RMSE is a widely used metric in recommendation systems because it measures the average magnitude of the prediction errors. By calculating the square root of the average squared differences between predicted and actual ratings, RMSE provides a direct insight into how well the model's predicted ratings align with the users' actual ratings.\n","\n","**Business Impact:** A lower RMSE indicates that the model's predictions are closer to the actual ratings, reducing the risk of recommending books that users might not like. Accurate predictions lead to higher user satisfaction and trust in the recommendation system, which can enhance user retention and increase sales or engagement.\n","\n","**2. Precision, Recall, and F1 Score:**\n","\n","Why they were chosen:\n","\n","Precision measures the proportion of relevant books among the recommended ones. High precision ensures that users are presented with books they are likely to enjoy.\n","\n","Recall measures the proportion of relevant books that were recommended out of all relevant books available. High recall ensures that the system is capturing a broad range of user interests.\n","\n","F1 Score balances precision and recall, providing a single metric that reflects both false positives and false negatives in recommendations.\n","\n","**Business Impact:** High precision reduces the chances of users being dissatisfied with irrelevant recommendations, while high recall ensures that users are not missing out on books they might like. The F1 Score provides a balanced view, helping to ensure that the recommendation system is both effective and efficient, leading to better user experiences and potentially higher sales."],"metadata":{"id":"jHVz9hHDKFms"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"cBFFvTBNJzUa"}},{"cell_type":"markdown","source":["The final model chosen for the book recommendation system is the Hybrid Model, which combines Collaborative Filtering (using SVD) and Content-Based Filtering (using FAISS). This hybrid approach was selected for several compelling reasons:\n","\n","**1. Strengths of Both Models:**\n","\n","**Collaborative Filtering (SVD):**\n","\n","Strength: The SVD model excels at capturing latent factors in user-book interactions, allowing it to make personalized recommendations based on users' past behavior (e.g., ratings). It can suggest books that users might not have explicitly shown interest in but are likely to enjoy based on similar users' preferences.\n","Weakness: Collaborative filtering alone can suffer from the \"cold start\" problem, where it struggles to make recommendations for new users or new books that lack sufficient rating history.\n","\n","**Content-Based Filtering (FAISS):**\n","\n","Strength: FAISS-based content filtering leverages the actual content of the books (e.g., descriptions, authors, publishers) to find similar items. It can recommend books based on textual and other metadata, which is particularly useful when dealing with new books or when explicit user ratings are sparse.\n","Weakness: Content-based filtering alone might recommend books that are too similar to what the user has already read, leading to a narrow range of suggestions.\n","\n","**2. Balanced and Comprehensive Recommendations:**\n","\n","The hybrid model effectively mitigates the weaknesses of each individual approach by combining their strengths. By integrating collaborative filtering, the system leverages user interaction data to offer diverse recommendations. Simultaneously, content-based filtering ensures that recommendations are relevant to the specific content attributes of the books.\n","This approach allows the system to recommend books that are both personalized (through collaborative filtering) and relevant to the user's interests or search queries (through content-based filtering)."],"metadata":{"id":"6ksF5Q1LKTVm"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"HvGl1hHyA_VK"}},{"cell_type":"markdown","source":["The model used for the final book recommendation system is a Hybrid Model that combines Collaborative Filtering (using SVD) and Content-Based Filtering (using FAISS). Here's an explanation of how these models work, along with an approach to feature importance using a model explainability tool.\n","\n","**1. Collaborative Filtering (SVD)**\n","\n","How It Works:\n","\n","Singular Value Decomposition (SVD) is a matrix factorization technique used in collaborative filtering. In this context, it decomposes the user-item interaction matrix (e.g., user-book ratings) into latent factors that represent underlying patterns in user preferences and book attributes.\n","\n","Latent Factors: These are abstract dimensions that capture user preferences and item characteristics. For instance, one latent factor might capture a preference for a specific genre, while another might reflect a preference for books by a certain author.\n","\n","Prediction: The model predicts a user’s rating for a book by estimating how closely the book's latent factors align with the user's latent preferences.\n","\n","Feature Importance in SVD:\n","\n","In SVD, the concept of \"feature importance\" is not as direct as in tree-based models like Random Forests. However, you can interpret the importance of\n","\n","features through:\n","\n","Latent Factors: These represent the most significant patterns in user preferences and item characteristics.\n","Bias Terms: The model can also include bias terms for users and items, capturing individual tendencies (e.g., a user generally gives higher ratings).\n","\n","**2. Content-Based Filtering (FAISS)**\n","\n","How It Works:\n","\n","TF-IDF Vectorization: The content-based filtering uses TF-IDF (Term Frequency-Inverse Document Frequency) to convert the textual content of books (e.g., titles, authors, descriptions) into numerical vectors. These vectors represent the importance of words in the context of the entire dataset.\n","\n","FAISS (Facebook AI Similarity Search): FAISS is used to quickly search for and retrieve similar items based on these vectors. The content-based model recommends books that are similar to the ones the user has shown interest in, based on textual similarity.\n","\n","Feature Importance in FAISS:\n","\n","TF-IDF Weights: The importance of features in this model can be interpreted through the TF-IDF weights. Higher TF-IDF weights indicate that a term is particularly important in distinguishing one book from others.\n","\n","Cosine Similarity: FAISS relies on cosine similarity to measure the distance between vectors, meaning the terms that most distinguish a book’s content (those with higher TF-IDF weights) are crucial in determining similarity."],"metadata":{"id":"YnvVTiIxBL-C"}},{"cell_type":"markdown","source":["## ***8.*** ***Future Work (Optional)***"],"metadata":{"id":"EyNgTHvd2WFk"}},{"cell_type":"markdown","source":["### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"],"metadata":{"id":"KH5McJBi2d8v"}},{"cell_type":"code","source":["# Save the File"],"metadata":{"id":"bQIANRl32f4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"],"metadata":{"id":"iW_Lq9qf2h6X"}},{"cell_type":"code","source":["# Load the File and predict unseen data."],"metadata":{"id":"oEXk9ydD2nVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"],"metadata":{"id":"-Kee-DAl2viO"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["**Conclusion:**\n","\n","The project successfully developed a sophisticated hybrid book recommendation system that effectively combines collaborative filtering and content-based filtering. Through careful tuning and evaluation, the model achieved a balance between accuracy and relevance, making it a valuable tool for enhancing user experience and driving business success. The use of model explainability tools like SHAP further added transparency, allowing stakeholders to understand and trust the recommendation process."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}